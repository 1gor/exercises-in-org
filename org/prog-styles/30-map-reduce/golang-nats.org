#+TITLE: Counting words in Go lang

** Golang monolith version

*** Start the NATS server

From a docker container:

#+name: nats-server
#+BEGIN_SRC sh :results output code
sudo docker run -p 4222:4222 apcera/gnatsd
#+END_SRC

The channels involved for the counting words job
to be distributed are:

- =pride-prejudice.discovery= ::
   Used to discover counting nodes that exist within the system.
   Nodes that can compute words send a payload with their =id=.
   Note: In a truly distributed run, they would announce more info
   such as where in the datacenter are they located.

- =pride-prejudice.requests= :: 
   Used by the aggregator to announce to nodes that a computation is needed to be done.

- =pride-prejudice.id.compute= ::
   Used by the aggregator to dispatch counting words requests to the node that id.
     
- =pride-prejudice.responses= ::
   Used by the aggregator to receive the computation and accumulate the results.

*** Aggregator

This process will be in charge of dispatching a range of the lines
in the text and dispatch the task to another node so that it computes
the word frequency computation.

#+name: aggregator
#+begin_src ruby :sleep 5
  require 'nats/client'
  require 'json'

  NATS.start {

    # Run options
    $stdout.sync = true
    ["TERM", "INT"].each { |sig| trap(sig) { NATS.stop } }
    SRC_ROOT   = File.join(File.expand_path("."), "src", "exercises-in-programming-style")
    PRIDE_AND_PREJUDICE = File.join(SRC_ROOT, "pride-and-prejudice.txt")
    STOP_WORDS = File.join(SRC_ROOT, 'stop_words.txt')

    # Compute the stop words once.
    # This payload information is small enough that it will be transmitted
    # to the frequency counters via the channel
    @stop_words = File.read(STOP_WORDS).split(',')
    @stop_words << ('a'..'z').to_a # also the alphabet
    @stop_words.flatten!.uniq!

    # Initialize
    @words = Hash.new {|h,k| h[k] = 0 }
    @available_computing_nodes = []

    # Discovery Channel
    NATS.subscribe('pride-prejudice.discovery') do |msg, reply, sub|
      computing_node = JSON.parse(msg)
      unless @available_computing_nodes.include?(computing_node)
        puts "[DISCOVERED]      :: #{computing_node}"
        @available_computing_nodes << computing_node
        puts "[AVAILABLE NODES] :: #{@available_computing_nodes.count}"
      end
    end

    # {"id"=>3, "results"=>{"words"=>[{"test"=>1}]}}
    NATS.subscribe('pride-prejudice.responses') do |msg, reply, sub|
      results = JSON.parse(msg)
      puts "[DONE]      :: Job #{results['id']} is done."

      # Mark the job as done
      @chunks[results['id']][:done]    = true

      begin
        # Use the partial results and start to count the words
        counted_words = results['results']['words']
        counted_words.each_pair do |w, c|
          @words[w] += c
        end
      rescue => e
        puts "Error while trying to count the words..."
        puts e
        puts e.backtrace
      end

      puts "TOP counted words so far"
      @words.sort {|a,b| a[1] <=> b[1]}.reverse[0...25].each do |k, v|
        puts "#{k}  -  #{v}"
      end
    end

    puts "Waiting 5 seconds to get resources for the job..."
    EM.add_timer(5) do
      pride_and_prejudice_text  = File.read(PRIDE_AND_PREJUDICE)
      total_lines = pride_and_prejudice_text.lines.count
      puts "Total lines to split: #{total_lines}"

      # Most likely cannot split the computation perfectly into the number of nodes,
      # so we take the remaining lines and add them to the first batch
      chunk_size = total_lines / (@available_computing_nodes.count)
      out_of_chunk = total_lines % @available_computing_nodes.count
      puts "Chunk size per node: #{chunk_size}"

      # Read the file, count the number of lines, and divide in chunks
      # according to the number of available nodes
      @chunks = {} # {index => {:start, :end, :done, :stop_words }}
      chunk_start = 0
      chunk_end   = 0
      1.upto(@available_computing_nodes.count) do |n|
        chunk_end += chunk_size
        if out_of_chunk > 0
          chunk_size += out_of_chunk
          out_of_chunk = 0
        end
        chunk_end  = [chunk_end, total_lines].min
        @chunks[n]  = {:start => chunk_start, :end => chunk_end, :done => false, :stop_words => @stop_words }
        chunk_start = chunk_end + 1
      end

      @chunks.each do |job|
        job_id, range = job

        # Only want one checker to respond to this
        NATS.request('pride-prejudice.requests', nil, :max => 1) do |response|
          node = JSON.parse(response)
          puts "[REQUEST]   :: Job ##{job_id} needs to be done. Anyone can help? Range is (#{range[:start]}:#{range[:end]})"
          NATS.publish("pride-prejudice.#{node['id']}.compute", job.to_json) do
            puts "[HOPING]    :: #{range[:start]} -- #{range[:end]} to be done by #{node['id']}."
          end
        end
      end
    end
  }
#+END_SRC

*** TODO Word Frequency Counter

This will receive a chunk of words to process, and reply 
with the partial computed frequency when done.

Delay the start of the process so that the nats server and aggregator are ready.

**** Counter in Golang

#+BEGIN_SRC go :tangle src/prog-styles/map-reduce-via-nats-golang/run.go :mkdirp true :sleep 2
package main

import (
        //        "runtime"  // needed for Goexit of goroutines
        "log"
        "time"
        "math/rand"
        "github.com/apcera/nats"
	  "encoding/json"
)

type Info struct {
  Id int `json: id`
}

func main() {

  // Generating a info json string to announce
  rand.Seed(time.Now().UTC().UnixNano())
  id   := rand.Int()
  info := Info{ id }
  infoJSON, _ := json.Marshal(info)

  log.Println("Connecting to NATS at ", nats.DefaultURL)
  natsConnection, err := nats.Connect(nats.DefaultURL)
  if err != nil {
    log.Fatalf("Could not connect!", err)
  }

  // Periodic timer to send discovery messages every second
  ticker := time.NewTicker(1 * time.Second)
  go func() {
    for {
      select {
      case <- ticker.C:
        // How to send JSON...
        natsConnection.Publish("pride-prejudice.discovery", infoJSON)
      }
    }
  }()

  time.Sleep(30 * time.Second) // timeout after 30 seconds
}
#+END_SRC

**** Dependencies

#+name: go-get-dependencies
#+BEGIN_SRC sh :dir src/prog-styles/map-reduce-via-nats-golang
export GOPATH=`pwd`
go get -d
#+END_SRC

**** Run

#+name: run-frequency-counter
#+BEGIN_SRC sh 
export GOPATH="`pwd`/src/prog-styles/map-reduce-via-nats-golang"
go run src/prog-styles/map-reduce-via-nats-golang/run.go
#+END_SRC
*** Snippets

#+BEGIN_SRC go :results output code
package main

import (
  "fmt"
  "math/rand"
  "time"
  "encoding/json"
)

type Info struct {
  Id int `json:"id"`
}

func main() {
  rand.Seed(time.Now().UTC().UnixNano())
  id := rand.Int()
  info := Info{ id }
  infoJSON, _ := json.Marshal(info)
  fmt.Println(string(infoJSON))
}
#+END_SRC

